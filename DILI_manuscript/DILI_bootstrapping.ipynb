{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Import Necessary Packages --- ###\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve,auc, roc_auc_score, accuracy_score, precision_recall_curve, auc, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from gensim import models\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Define Useful Functions --- ###\n",
    "def modelEval(y_true, y_preds, predict_probs):\n",
    "    auroc = (roc_auc_score(y_true, predict_probs))\n",
    "    accuracy = (accuracy_score(y_true, y_preds))\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    precision, recall, threshold = precision_recall_curve(y_true, predict_probs)\n",
    "    auprc = auc(recall, precision)\n",
    "    return {\"auroc\": auroc, \"accuracy\": accuracy, \"auprc\": auprc, \"f1_score\": f1}\n",
    "\n",
    "\n",
    "def getPredicts(clf, X):\n",
    "    predict_probs = clf.predict_proba(X)[:, 1] #Predicted probability for the positive label\n",
    "    predicts = clf.predict(X)\n",
    "    return predicts, predict_probs\n",
    "\n",
    "\n",
    "def retrieve_top_words(clf, vectorizer, top_k=5, top_positve_words=True):\n",
    "    clf_name = clf.__class__.__name__\n",
    "    if clf_name == 'LogisticRegression':\n",
    "        coef_arr = np.array(clf.coef_).squeeze()\n",
    "    elif clf_name == 'RandomForestClassifier':\n",
    "        coef_arr = np.array(clf.feature_importances_).squeeze()\n",
    "    else:\n",
    "        raise (Exception('Classifier is not LR nor RF, cannot retrieve importance coef.'))\n",
    "\n",
    "    Name_list = vectorizer.get_feature_names()\n",
    "    if top_positve_words:\n",
    "        # print('Retrieving Top '+str(top_k)+' words for positive samples')\n",
    "        top_k_idx = coef_arr.argsort()[::-1][0:top_k]\n",
    "    else:\n",
    "        # print('Retrieving Top '+str(top_k)+' words for negative samples')\n",
    "        top_k_idx = coef_arr.argsort()[0:top_k]\n",
    "    top_k_words = []\n",
    "    for idx in top_k_idx:\n",
    "        top_k_words.append(Name_list[idx])\n",
    "    # print(top_k_words)\n",
    "    return (top_k_words)\n",
    "\n",
    "def plot_ROC(y_true, y_pred, legend, lw):\n",
    "    '''\n",
    "    This function plots the ROC based on y_true and y_pred\n",
    "    :param y_true: The ground truth of the samples\n",
    "    :param y_pred: The predicted probablity of the samples\n",
    "    :param legend: Legend of the curve\n",
    "    :return: None\n",
    "    '''\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw = lw, label = legend + ' AUC=%0.3f' % auroc)\n",
    "\n",
    "def plot_PRC(y_true, y_pred, legend, lw):\n",
    "    '''\n",
    "    This function plots the precision-recall curves based on y_true and y_pred\n",
    "    :param y_true: The ground truth of the samples\n",
    "    :param y_pred: The predicted probablity of the samples\n",
    "    :param legend: Legend of the curve\n",
    "    :return: None\n",
    "    '''\n",
    "    pre, rec, _ = precision_recall_curve(y_true, y_pred)\n",
    "    auroc = auc(rec, pre)\n",
    "    plt.plot(rec, pre, lw = lw, label = legend + ' AUC=%0.3f' % auroc)\n",
    "\n",
    "class w2v_vectorizer():\n",
    "\n",
    "    def __init__(self, wv):\n",
    "        '''\n",
    "        This functin initialize the word2vec model\n",
    "        :param wv: a gensim word2vec model\n",
    "        '''\n",
    "        self.model = wv\n",
    "        pass\n",
    "\n",
    "    def transform(self,corpus):\n",
    "        '''\n",
    "        This function vectorize each document in the corpus\n",
    "        :param corpus: pd.series of documents\n",
    "        :return: feature: vectorized documents\n",
    "        '''\n",
    "        feature = np.empty((corpus.shape[0],200))\n",
    "        sent_lst = list(corpus)\n",
    "        print('W2V vectorization: get word vectors')\n",
    "        vec_lst = [[self.model[word] for word in sent if word in self.model.vocab] for sent in tqdm(sent_lst)]\n",
    "        print('W2V vectorization: get sentence vectors')\n",
    "        for i in tqdm(list(range(feature.shape[0]))):\n",
    "            feature[i,:] = np.mean(vec_lst[i],axis=0,keepdims=False) # continuous bag-of-word with average pooling\n",
    "        return feature\n",
    "\n",
    "\n",
    "def ErrorAnalysis(preds,GT_label,GT_text):\n",
    "    '''\n",
    "    Return DataFrame of FN and FP texts and indexes\n",
    "\n",
    "    args:\n",
    "    preds: predicted labels\n",
    "    GT_label: ground truth labels\n",
    "    val_text: original text before vectorization\n",
    "\n",
    "    output:\n",
    "    Error_DF: DataFrame that contains FN text and index, FP text and index\n",
    "    '''\n",
    "    False_Neg = []\n",
    "    False_Pos = []\n",
    "    False_Neg_Idx = []\n",
    "    False_Pos_Idx = []\n",
    "    for idx in range(preds.shape[0]):\n",
    "        if preds[idx] == 1 and GT_label[idx] == 0:\n",
    "            False_Pos.append(GT_text[idx])\n",
    "            False_Pos_Idx.append(idx)\n",
    "        elif preds[idx] == 0 and GT_label[idx] == 1:\n",
    "            False_Neg.append(GT_text[idx])\n",
    "            False_Neg_Idx.append(idx)\n",
    "    Error_dict = {'False_Positive':False_Pos,'False_Negative':False_Neg,'False_Pos_Idx':False_Pos_Idx,'False_Neg_Idx':False_Neg_Idx}\n",
    "    Error_DF = pd.DataFrame.from_dict(Error_dict,orient='index').transpose()\n",
    "    return Error_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Bootstrapping on the 80% trainng data for non-ensemble learning models --- ###\n",
    "\n",
    "#Change here to choose corpus from STEM_TEXT or CLEAN_TEXT\n",
    "TEXT = 'STEM_TEXT'\n",
    "\n",
    "#Load Dataset\n",
    "Train_Data, Val_Data = pd.read_csv(\"Data/train.csv\"),pd.read_csv(\"Data/val.csv\")\n",
    "train_corpus, val_corpus= Train_Data[TEXT], Val_Data[TEXT]\n",
    "\n",
    "#Preprocessing labels form boolean to int\n",
    "Y_train, Y_val = Train_Data['label'].astype(int), Val_Data['label'].astype(int)\n",
    "\n",
    "#Instancing classifier (SVM and MLP take a lot time to run!)\n",
    "clf_dict = {\n",
    "    'LR':LogisticRegression(max_iter=200)\n",
    "    #,'SVM':SVC(probability=True)\n",
    "    #,'RF':RandomForestClassifier()\n",
    "    #,'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "### --- BOW --- ###\n",
    "\n",
    "#Instancing vectorizer\n",
    "vectorizer_dict = {\n",
    "    'BOW':text.CountVectorizer()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW\n"
     ]
    }
   ],
   "source": [
    "#select each of the vectorizer\n",
    "for vect_NAME in vectorizer_dict:\n",
    "    print(vect_NAME)\n",
    "    vectorizer = vectorizer_dict[vect_NAME]\n",
    "\n",
    "    #Fit clf\n",
    "    if vect_NAME == 'BOW':\n",
    "        clf = LogisticRegression(C = 0.1,max_iter=1000,penalty='l2')\n",
    "    else:\n",
    "        clf = LogisticRegression(C = 10,max_iter=1000,penalty='l2')\n",
    "    \n",
    "    #bootstrapping experiments: initialize the performance recorders\n",
    "    vectorization_time = []\n",
    "    modeling_time = []\n",
    "    auroc = []\n",
    "    auprc = []\n",
    "    f1_score_recorder = []\n",
    "    accuracy = []\n",
    "    predicted_prob = []\n",
    "    train_prob = []\n",
    "    train_label = []\n",
    "    for i in range(100):\n",
    "        np.random.seed(i)\n",
    "        idx = np.random.choice(train_corpus.shape[0],train_corpus.shape[0],replace=True)\n",
    "        X_train_boot = train_corpus[idx]\n",
    "        Y_train_boot = Y_train[idx]\n",
    "        train_label.append(Y_train_boot)\n",
    "        \n",
    "        \n",
    "        #Fit vectorizer using train corpus\n",
    "        tik = time.time()\n",
    "        X_train = vectorizer.fit_transform(X_train_boot)\n",
    "        X_val = vectorizer.transform(val_corpus)\n",
    "        tok = time.time()\n",
    "        vectorization_time.append(tok-tik)\n",
    "        \n",
    "        #Fit classifier using logistic regression\n",
    "        tik = time.time()\n",
    "        clf.fit(X_train,Y_train_boot)\n",
    "        tok = time.time()\n",
    "        modeling_time.append(tok-tik)\n",
    "        \n",
    "        \n",
    "        #Make prediction and evaluate the prediction\n",
    "        preds, pred_probs = getPredicts(clf, X_val)\n",
    "        predicted_prob.append(pred_probs)\n",
    "        result = modelEval(Y_val, preds, pred_probs)\n",
    "        \n",
    "        #Get training probability\n",
    "        train_preds, train_pred_probs = getPredicts(clf, X_train)\n",
    "        train_prob.append(train_pred_probs)\n",
    "        \n",
    "        auroc.append(result['auroc'])\n",
    "        auprc.append(result['auprc'])\n",
    "        accuracy.append(result['accuracy'])\n",
    "        f1_score_recorder.append(result['f1_score'])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC                 0.983010\n",
      "AUPRC                 0.982830\n",
      "Accuracy              0.944020\n",
      "F1_score              0.945174\n",
      "Vectorization_Time    2.630324\n",
      "Modeling_Time         2.246226\n",
      "dtype: float64\n",
      "AUROC                 0.981517\n",
      "AUPRC                 0.980647\n",
      "Accuracy              0.939810\n",
      "F1_score              0.941134\n",
      "Vectorization_Time    2.489900\n",
      "Modeling_Time         1.614048\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.984492\n",
      "AUPRC                 0.984944\n",
      "Accuracy              0.948258\n",
      "F1_score              0.949381\n",
      "Vectorization_Time    2.823604\n",
      "Modeling_Time         2.775940\n",
      "Name: 0.975, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "result_df.to_csv('.//Result//Bootstrapping_'+vect_NAME+'.csv', index = False)\n",
    "np.save('.//Result//Bootstrapping_predicted_probability_'+vect_NAME+'.npy',np.array(predicted_prob))\n",
    "np.save('.//Result//Bootstrapping_predicted_probability_training_'+vect_NAME+'.npy',np.array(train_prob))\n",
    "np.save('.//Result//Bootstrapping_label_training_'+vect_NAME+'.npy',np.array(train_label))\n",
    "print(result_df.mean())\n",
    "print(result_df.quantile(0.025))\n",
    "print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "AUROC                 0.987890\n",
      "AUPRC                 0.988493\n",
      "Accuracy              0.952974\n",
      "F1_score              0.953637\n",
      "Vectorization_Time    2.214791\n",
      "Modeling_Time         1.817068\n",
      "dtype: float64\n",
      "AUROC                 0.986991\n",
      "AUPRC                 0.987513\n",
      "Accuracy              0.948944\n",
      "F1_score              0.949411\n",
      "Vectorization_Time    1.215391\n",
      "Modeling_Time         0.536576\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.988805\n",
      "AUPRC                 0.989441\n",
      "Accuracy              0.956741\n",
      "F1_score              0.957341\n",
      "Vectorization_Time    2.816845\n",
      "Modeling_Time         3.499377\n",
      "Name: 0.975, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### --- TF-IDF --- ###\n",
    "#Instancing vectorizer\n",
    "vectorizer_dict = {\n",
    "    'TFIDF':text.TfidfVectorizer()\n",
    "}\n",
    "\n",
    "#select each of the vectorizer\n",
    "for vect_NAME in vectorizer_dict:\n",
    "    print(vect_NAME)\n",
    "    vectorizer = vectorizer_dict[vect_NAME]\n",
    "\n",
    "    #Fit clf\n",
    "    if vect_NAME == 'BOW':\n",
    "        clf = LogisticRegression(C = 0.1,max_iter=1000,penalty='l2')\n",
    "    else:\n",
    "        clf = LogisticRegression(C = 10,max_iter=1000,penalty='l2')\n",
    "    \n",
    "    #bootstrapping experiments: initialize the performance recorders\n",
    "    vectorization_time = []\n",
    "    modeling_time = []\n",
    "    auroc = []\n",
    "    auprc = []\n",
    "    f1_score_recorder = []\n",
    "    accuracy = []\n",
    "    predicted_prob = []\n",
    "    train_prob = []\n",
    "    train_label = []\n",
    "    for i in range(100):\n",
    "        np.random.seed(i)\n",
    "        idx = np.random.choice(train_corpus.shape[0],train_corpus.shape[0],replace=True)\n",
    "        X_train_boot = train_corpus[idx]\n",
    "        Y_train_boot = Y_train[idx]\n",
    "        train_label.append(Y_train_boot)\n",
    "        \n",
    "        \n",
    "        #Fit vectorizer using train corpus\n",
    "        tik = time.time()\n",
    "        X_train = vectorizer.fit_transform(X_train_boot)\n",
    "        X_val = vectorizer.transform(val_corpus)\n",
    "        tok = time.time()\n",
    "        vectorization_time.append(tok-tik)\n",
    "        \n",
    "        #Fit classifier using logistic regression\n",
    "        tik = time.time()\n",
    "        clf.fit(X_train,Y_train_boot)\n",
    "        tok = time.time()\n",
    "        modeling_time.append(tok-tik)\n",
    "        \n",
    "        \n",
    "        #Make prediction and evaluate the prediction\n",
    "        preds, pred_probs = getPredicts(clf, X_val)\n",
    "        predicted_prob.append(pred_probs)\n",
    "        result = modelEval(Y_val, preds, pred_probs)\n",
    "        \n",
    "        #Get training probability\n",
    "        train_preds, train_pred_probs = getPredicts(clf, X_train)\n",
    "        train_prob.append(train_pred_probs)\n",
    "        \n",
    "        auroc.append(result['auroc'])\n",
    "        auprc.append(result['auprc'])\n",
    "        accuracy.append(result['accuracy'])\n",
    "        f1_score_recorder.append(result['f1_score'])\n",
    "    result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "    result_df.to_csv('.//Result//Bootstrapping_'+vect_NAME+'.csv', index = False)\n",
    "    np.save('.//Result//Bootstrapping_predicted_probability_'+vect_NAME+'.npy',np.array(predicted_prob))\n",
    "    np.save('.//Result//Bootstrapping_predicted_probability_training_'+vect_NAME+'.npy',np.array(train_prob))\n",
    "    np.save('.//Result//Bootstrapping_label_training_'+vect_NAME+'.npy',np.array(train_label))\n",
    "    print(result_df.mean())\n",
    "    print(result_df.quantile(0.025))\n",
    "    print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V2\n",
      "AUROC                 0.980034\n",
      "AUPRC                 0.981032\n",
      "Accuracy              0.939271\n",
      "F1_score              0.940312\n",
      "Vectorization_Time    0.000004\n",
      "Modeling_Time         0.983368\n",
      "dtype: float64\n",
      "AUROC                 0.978985\n",
      "AUPRC                 0.980009\n",
      "Accuracy              0.936290\n",
      "F1_score              0.937239\n",
      "Vectorization_Time    0.000002\n",
      "Modeling_Time         0.650753\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.981202\n",
      "AUPRC                 0.982183\n",
      "Accuracy              0.943198\n",
      "F1_score              0.944228\n",
      "Vectorization_Time    0.000005\n",
      "Modeling_Time         1.232835\n",
      "Name: 0.975, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Change here to choose corpus from STEM_TEXT or CLEAN_TEXT\n",
    "TEXT = 'CLEAN_TEXT'\n",
    "\n",
    "#Load Dataset\n",
    "Train_Data, Val_Data = pd.read_csv(\"Data/train.csv\"),pd.read_csv(\"Data/val.csv\")\n",
    "train_corpus, val_corpus= Train_Data[TEXT], Val_Data[TEXT]\n",
    "\n",
    "#Preprocessing labels form boolean to int\n",
    "Y_train, Y_val = Train_Data['label'].astype(int), Val_Data['label'].astype(int)\n",
    "\n",
    "#Instancing classifier (SVM and MLP take a lot time to run!)\n",
    "clf_dict = {\n",
    "    'LR':LogisticRegression(max_iter=200)\n",
    "    #,'SVM':SVC(probability=True)\n",
    "    #,'RF':RandomForestClassifier()\n",
    "    #,'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "#Instancing vectorizer\n",
    "vectorizer_dict = ['W2V2']\n",
    "\n",
    "#select each of the vectorizer\n",
    "for vect_NAME in vectorizer_dict:\n",
    "    print(vect_NAME)\n",
    "\n",
    "    #Fit clf\n",
    "    if 'W2V' in vect_NAME:\n",
    "        clf = LogisticRegression(C = 10,max_iter=1000,penalty='l2')\n",
    "    else:\n",
    "        clf = LogisticRegression(C = 1,max_iter=1000,penalty='l2')\n",
    "    \n",
    "    #bootstrapping experiments: initialize the performance recorders\n",
    "    vectorization_time = []\n",
    "    modeling_time = []\n",
    "    auroc = []\n",
    "    auprc = []\n",
    "    f1_score_recorder = []\n",
    "    accuracy = []\n",
    "    predicted_prob = []\n",
    "    \n",
    "    if vect_NAME == 'W2V1':\n",
    "        train_corpus = np.load('./Embeddings/W2V1_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/W2V1_CLEAN_val.npy')\n",
    "    elif vect_NAME == 'S2V':\n",
    "        train_corpus = np.load('./Embeddings/S2V_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/S2V_CLEAN_val.npy')\n",
    "    else:\n",
    "        train_corpus = np.load('./Embeddings/W2V2_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/W2V2_CLEAN_val.npy')\n",
    "    \n",
    "    for i in range(100):\n",
    "        np.random.seed(i)\n",
    "        idx = np.random.choice(train_corpus.shape[0],train_corpus.shape[0],replace=True)\n",
    "        X_train_boot = train_corpus[idx]\n",
    "        Y_train_boot = Y_train[idx]\n",
    "        \n",
    "        \n",
    "        #Fit vectorizer using train corpus\n",
    "        tik = time.time()\n",
    "        X_train = X_train_boot\n",
    "        X_val = val_corpus\n",
    "        tok = time.time()\n",
    "        vectorization_time.append(tok-tik)\n",
    "        \n",
    "        #Fit classifier using logistic regression\n",
    "        tik = time.time()\n",
    "        clf.fit(X_train,Y_train_boot)\n",
    "        tok = time.time()\n",
    "        modeling_time.append(tok-tik)\n",
    "        \n",
    "        \n",
    "        #Make prediction and evaluate the prediction\n",
    "        preds, pred_probs = getPredicts(clf, X_val)\n",
    "        predicted_prob.append(pred_probs)\n",
    "        result = modelEval(Y_val, preds, pred_probs)\n",
    "        \n",
    "        auroc.append(result['auroc'])\n",
    "        auprc.append(result['auprc'])\n",
    "        accuracy.append(result['accuracy'])\n",
    "        f1_score_recorder.append(result['f1_score'])\n",
    "        \n",
    "    result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "    result_df.to_csv('./Result/Bootstrapping_'+vect_NAME+'.csv', index = False)\n",
    "    np.save('./Result/Bootstrapping_predicted_probability_'+vect_NAME+'.npy',np.array(predicted_prob))\n",
    "    print(result_df.mean())\n",
    "    print(result_df.quantile(0.025))\n",
    "    print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2V\n",
      "AUROC                 0.985377\n",
      "AUPRC                 0.986466\n",
      "Accuracy              0.949440\n",
      "F1_score              0.950300\n",
      "Vectorization_Time    0.000008\n",
      "Modeling_Time         0.455067\n",
      "dtype: float64\n",
      "AUROC                 0.984218\n",
      "AUPRC                 0.985527\n",
      "Accuracy              0.946498\n",
      "F1_score              0.947347\n",
      "Vectorization_Time    0.000003\n",
      "Modeling_Time         0.360581\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.986376\n",
      "AUPRC                 0.987385\n",
      "Accuracy              0.953203\n",
      "F1_score              0.954104\n",
      "Vectorization_Time    0.000005\n",
      "Modeling_Time         0.540543\n",
      "Name: 0.975, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Change here to choose corpus from STEM_TEXT or CLEAN_TEXT\n",
    "TEXT = 'CLEAN_TEXT'\n",
    "\n",
    "#Load Dataset\n",
    "Train_Data, Val_Data = pd.read_csv(\"Data/train.csv\"),pd.read_csv(\"Data/val.csv\")\n",
    "train_corpus, val_corpus= Train_Data[TEXT], Val_Data[TEXT]\n",
    "\n",
    "#Preprocessing labels form boolean to int\n",
    "Y_train, Y_val = Train_Data['label'].astype(int), Val_Data['label'].astype(int)\n",
    "\n",
    "#Instancing classifier (SVM and MLP take a lot time to run!)\n",
    "clf_dict = {\n",
    "    'LR':LogisticRegression(max_iter=200)\n",
    "    #,'SVM':SVC(probability=True)\n",
    "    #,'RF':RandomForestClassifier()\n",
    "    #,'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "#Instancing vectorizer\n",
    "vectorizer_dict = ['S2V']\n",
    "\n",
    "#select each of the vectorizer\n",
    "for vect_NAME in vectorizer_dict:\n",
    "    print(vect_NAME)\n",
    "\n",
    "    #Fit clf\n",
    "    if 'W2V' in vect_NAME:\n",
    "        clf = LogisticRegression(C = 10,max_iter=1000,penalty='l2')\n",
    "    else:\n",
    "        clf = LogisticRegression(C = 1,max_iter=1000,penalty='l2')\n",
    "    \n",
    "    #bootstrapping experiments: initialize the performance recorders\n",
    "    vectorization_time = []\n",
    "    modeling_time = []\n",
    "    auroc = []\n",
    "    auprc = []\n",
    "    f1_score_recorder = []\n",
    "    accuracy = []\n",
    "    predicted_prob = []\n",
    "    \n",
    "    if vect_NAME == 'W2V1':\n",
    "        train_corpus = np.load('./Embeddings/W2V1_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/W2V1_CLEAN_val.npy')\n",
    "    elif vect_NAME == 'S2V':\n",
    "        train_corpus = np.load('./Embeddings/S2V_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/S2V_CLEAN_val.npy')\n",
    "    else:\n",
    "        train_corpus = np.load('./Embeddings/W2V2_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/W2V2_CLEAN_val.npy')\n",
    "    \n",
    "    for i in range(100):\n",
    "        np.random.seed(i)\n",
    "        idx = np.random.choice(train_corpus.shape[0],train_corpus.shape[0],replace=True)\n",
    "        X_train_boot = train_corpus[idx]\n",
    "        Y_train_boot = Y_train[idx]\n",
    "        \n",
    "        \n",
    "        #Fit vectorizer using train corpus\n",
    "        tik = time.time()\n",
    "        X_train = X_train_boot\n",
    "        X_val = val_corpus\n",
    "        tok = time.time()\n",
    "        vectorization_time.append(tok-tik)\n",
    "        \n",
    "        #Fit classifier using logistic regression\n",
    "        tik = time.time()\n",
    "        clf.fit(X_train,Y_train_boot)\n",
    "        tok = time.time()\n",
    "        modeling_time.append(tok-tik)\n",
    "        \n",
    "        \n",
    "        #Make prediction and evaluate the prediction\n",
    "        preds, pred_probs = getPredicts(clf, X_val)\n",
    "        predicted_prob.append(pred_probs)\n",
    "        result = modelEval(Y_val, preds, pred_probs)\n",
    "        \n",
    "        auroc.append(result['auroc'])\n",
    "        auprc.append(result['auprc'])\n",
    "        accuracy.append(result['accuracy'])\n",
    "        f1_score_recorder.append(result['f1_score'])\n",
    "        \n",
    "    result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "    result_df.to_csv('./Result/Bootstrapping_'+vect_NAME+'.csv', index = False)\n",
    "    np.save('./Result/Bootstrapping_predicted_probability_'+vect_NAME+'.npy',np.array(predicted_prob))\n",
    "    print(result_df.mean())\n",
    "    print(result_df.quantile(0.025))\n",
    "    print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V1\n",
      "AUROC                 0.978091\n",
      "AUPRC                 0.977870\n",
      "Accuracy              0.936269\n",
      "F1_score              0.937476\n",
      "Vectorization_Time    0.000003\n",
      "Modeling_Time         0.374294\n",
      "dtype: float64\n",
      "AUROC                 0.977181\n",
      "AUPRC                 0.977143\n",
      "Accuracy              0.932585\n",
      "F1_score              0.933811\n",
      "Vectorization_Time    0.000002\n",
      "Modeling_Time         0.274849\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.979008\n",
      "AUPRC                 0.978689\n",
      "Accuracy              0.939476\n",
      "F1_score              0.940741\n",
      "Vectorization_Time    0.000004\n",
      "Modeling_Time         0.461916\n",
      "Name: 0.975, dtype: float64\n",
      "W2V2\n",
      "AUROC                 0.980034\n",
      "AUPRC                 0.981032\n",
      "Accuracy              0.939271\n",
      "F1_score              0.940312\n",
      "Vectorization_Time    0.000003\n",
      "Modeling_Time         0.981364\n",
      "dtype: float64\n",
      "AUROC                 0.978985\n",
      "AUPRC                 0.980009\n",
      "Accuracy              0.936290\n",
      "F1_score              0.937239\n",
      "Vectorization_Time    0.000002\n",
      "Modeling_Time         0.648021\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.981202\n",
      "AUPRC                 0.982183\n",
      "Accuracy              0.943198\n",
      "F1_score              0.944228\n",
      "Vectorization_Time    0.000003\n",
      "Modeling_Time         1.262235\n",
      "Name: 0.975, dtype: float64\n",
      "S2V\n",
      "AUROC                 0.985376\n",
      "AUPRC                 0.986466\n",
      "Accuracy              0.949440\n",
      "F1_score              0.950300\n",
      "Vectorization_Time    0.000009\n",
      "Modeling_Time         0.558477\n",
      "dtype: float64\n",
      "AUROC                 0.984218\n",
      "AUPRC                 0.985527\n",
      "Accuracy              0.946498\n",
      "F1_score              0.947347\n",
      "Vectorization_Time    0.000003\n",
      "Modeling_Time         0.448621\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.986376\n",
      "AUPRC                 0.987385\n",
      "Accuracy              0.953203\n",
      "F1_score              0.954104\n",
      "Vectorization_Time    0.000006\n",
      "Modeling_Time         0.672034\n",
      "Name: 0.975, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Change here to choose corpus from STEM_TEXT or CLEAN_TEXT\n",
    "TEXT = 'CLEAN_TEXT'\n",
    "\n",
    "#Load Dataset\n",
    "Train_Data, Val_Data = pd.read_csv(\"Data/train.csv\"),pd.read_csv(\"Data/val.csv\")\n",
    "train_corpus, val_corpus= Train_Data[TEXT], Val_Data[TEXT]\n",
    "\n",
    "#Preprocessing labels form boolean to int\n",
    "Y_train, Y_val = Train_Data['label'].astype(int), Val_Data['label'].astype(int)\n",
    "\n",
    "#Instancing classifier (SVM and MLP take a lot time to run!)\n",
    "clf_dict = {\n",
    "    'LR':LogisticRegression(max_iter=200)\n",
    "    #,'SVM':SVC(probability=True)\n",
    "    #,'RF':RandomForestClassifier()\n",
    "    #,'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "#Instancing vectorizer\n",
    "vectorizer_dict = ['W2V1','W2V2','S2V']\n",
    "\n",
    "#select each of the vectorizer\n",
    "for vect_NAME in vectorizer_dict:\n",
    "    print(vect_NAME)\n",
    "\n",
    "    #Fit clf\n",
    "    if 'W2V' in vect_NAME:\n",
    "        clf = LogisticRegression(C = 10,max_iter=1000,penalty='l2')\n",
    "    else:\n",
    "        clf = LogisticRegression(C = 1,max_iter=1000,penalty='l2')\n",
    "    \n",
    "    #bootstrapping experiments: initialize the performance recorders\n",
    "    vectorization_time = []\n",
    "    modeling_time = []\n",
    "    auroc = []\n",
    "    auprc = []\n",
    "    f1_score_recorder = []\n",
    "    accuracy = []\n",
    "    predicted_prob = []\n",
    "    train_prob = []\n",
    "    train_label = []\n",
    "    \n",
    "    if vect_NAME == 'W2V1':\n",
    "        train_corpus = np.load('./Embeddings/W2V1_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/W2V1_CLEAN_val.npy')\n",
    "    elif vect_NAME == 'S2V':\n",
    "        train_corpus = np.load('./Embeddings/S2V_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/S2V_CLEAN_val.npy')\n",
    "    else:\n",
    "        train_corpus = np.load('./Embeddings/W2V2_CLEAN_train.npy')\n",
    "        val_corpus = np.load('./Embeddings/W2V2_CLEAN_val.npy')\n",
    "    \n",
    "    for i in range(100):\n",
    "        np.random.seed(i)\n",
    "        idx = np.random.choice(train_corpus.shape[0],train_corpus.shape[0],replace=True)\n",
    "        X_train_boot = train_corpus[idx]\n",
    "        Y_train_boot = Y_train[idx]\n",
    "        train_label.append(Y_train_boot)\n",
    "        \n",
    "        \n",
    "        #Fit vectorizer using train corpus\n",
    "        tik = time.time()\n",
    "        X_train = X_train_boot\n",
    "        X_val = val_corpus\n",
    "        tok = time.time()\n",
    "        vectorization_time.append(tok-tik)\n",
    "        \n",
    "        #Fit classifier using logistic regression\n",
    "        tik = time.time()\n",
    "        clf.fit(X_train,Y_train_boot)\n",
    "        tok = time.time()\n",
    "        modeling_time.append(tok-tik)\n",
    "        \n",
    "        \n",
    "        #Make prediction and evaluate the prediction\n",
    "        preds, pred_probs = getPredicts(clf, X_val)\n",
    "        predicted_prob.append(pred_probs)\n",
    "        result = modelEval(Y_val, preds, pred_probs)\n",
    "        \n",
    "        #Get training probability\n",
    "        train_preds, train_pred_probs = getPredicts(clf, X_train)\n",
    "        train_prob.append(train_pred_probs)\n",
    "        \n",
    "        auroc.append(result['auroc'])\n",
    "        auprc.append(result['auprc'])\n",
    "        accuracy.append(result['accuracy'])\n",
    "        f1_score_recorder.append(result['f1_score'])\n",
    "        \n",
    "    result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "    result_df.to_csv('./Result/Bootstrapping_'+vect_NAME+'.csv', index = False)\n",
    "    np.save('./Result/Bootstrapping_predicted_probability_'+vect_NAME+'.npy',np.array(predicted_prob))\n",
    "    np.save('./Result/Bootstrapping_predicted_probability_training_'+vect_NAME+'.npy',np.array(train_prob))\n",
    "    print(result_df.mean())\n",
    "    print(result_df.quantile(0.025))\n",
    "    print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting the predicted probability of  TF-IDF   1:1 !\n",
      "Collecting the predicted probability of  TF-IDF   2:1 !\n",
      "Collecting the predicted probability of  TF-IDF   5:1 !\n",
      "Collecting the predicted probability of  W2V1   1:1 !\n",
      "Collecting the predicted probability of  W2V1   2:1 !\n",
      "Collecting the predicted probability of  W2V1   5:1 !\n",
      "Collecting the predicted probability of  W2V2   1:1 !\n",
      "Collecting the predicted probability of  W2V2   2:1 !\n",
      "Collecting the predicted probability of  W2V2   5:1 !\n",
      "Collecting the predicted probability of  S2V   1:1 !\n",
      "Collecting the predicted probability of  S2V   2:1 !\n",
      "Collecting the predicted probability of  S2V   5:1 !\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2841, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2841, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auroc': 0.9893583588039407, 'accuracy': 0.9570573741640267, 'auprc': 0.9900937497350172, 'f1_score': 0.9580756013745704}\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,Y_train)\n",
    "preds, pred_probs = getPredicts(clf, X_test)\n",
    "predicted_prob.append(pred_probs)\n",
    "result = modelEval(Y_test, preds, pred_probs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble\n",
      "AUROC                 0.535404\n",
      "AUPRC                 0.583458\n",
      "Accuracy              0.532506\n",
      "F1_score              0.460525\n",
      "Vectorization_Time    0.000002\n",
      "Modeling_Time         0.017045\n",
      "dtype: float64\n",
      "AUROC                 0.031261\n",
      "AUPRC                 0.315369\n",
      "Accuracy              0.057471\n",
      "F1_score              0.017354\n",
      "Vectorization_Time    0.000001\n",
      "Modeling_Time         0.011206\n",
      "Name: 0.025, dtype: float64\n",
      "AUROC                 0.965964\n",
      "AUPRC                 0.935857\n",
      "Accuracy              0.938974\n",
      "F1_score              0.941261\n",
      "Vectorization_Time    0.000003\n",
      "Modeling_Time         0.021765\n",
      "Name: 0.975, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Fit clf\n",
    "lr_clf = LogisticRegression(C = 0.1,max_iter=1000,penalty='l2')\n",
    "\n",
    "#bootstrapping experiments: initialize the performance recorders\n",
    "vectorization_time = []\n",
    "modeling_time = []\n",
    "auroc = []\n",
    "auprc = []\n",
    "f1_score_recorder = []\n",
    "accuracy = []\n",
    "predicted_prob = []\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    idx = np.random.choice(X_train.shape[0],X_train.shape[0],replace=True)\n",
    "    X_train_boot = X_train[idx]\n",
    "    Y_train_boot = Y_train[idx]\n",
    "\n",
    "\n",
    "    #Fit vectorizer using train corpus\n",
    "    tik = time.time()\n",
    "    tok = time.time()\n",
    "    vectorization_time.append(tok-tik)\n",
    "\n",
    "    #Fit classifier using logistic regression\n",
    "    tik = time.time()\n",
    "    clf.fit(X_train_boot,Y_train_boot)\n",
    "    tok = time.time()\n",
    "    modeling_time.append(tok-tik)\n",
    "\n",
    "\n",
    "    #Make prediction and evaluate the prediction\n",
    "    preds, pred_probs = getPredicts(clf, X_test)\n",
    "    predicted_prob.append(pred_probs)\n",
    "    result = modelEval(Y_test, preds, pred_probs)\n",
    "\n",
    "    auroc.append(result['auroc'])\n",
    "    auprc.append(result['auprc'])\n",
    "    accuracy.append(result['accuracy'])\n",
    "    f1_score_recorder.append(result['f1_score'])\n",
    "\n",
    "#     result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "#     result_df.to_csv('./Result/Bootstrapping_'+vect_NAME+'.csv', index = False)\n",
    "#     np.save('./Result/Bootstrapping_predicted_probability_'+vect_NAME+'.npy',np.array(predicted_prob))\n",
    "print(result_df.mean())\n",
    "print(result_df.quantile(0.025))\n",
    "print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auroc': 0.9889518865764034, 'accuracy': 0.9538894755367828, 'auprc': 0.9894425527028552, 'f1_score': 0.95499828237719}\n",
      "{'auroc': 0.9886366227511428, 'accuracy': 0.9545934530095037, 'auprc': 0.9893856488602633, 'f1_score': 0.9557764826876929}\n",
      "{'auroc': 0.9886762785782197, 'accuracy': 0.9545934530095037, 'auprc': 0.9894400813980319, 'f1_score': 0.9556548642145067}\n",
      "{'auroc': 0.9883228460193977, 'accuracy': 0.9531854980640619, 'auprc': 0.9889926446886722, 'f1_score': 0.9543739279588337}\n",
      "{'auroc': 0.988188511905175, 'accuracy': 0.9507215769095388, 'auprc': 0.9883953507953801, 'f1_score': 0.952054794520548}\n",
      "{'auroc': 0.9884234726806049, 'accuracy': 0.9521295318549806, 'auprc': 0.9890979958494277, 'f1_score': 0.9533287577213453}\n",
      "{'auroc': 0.9892041967761795, 'accuracy': 0.9549454417458642, 'auprc': 0.9898249773661048, 'f1_score': 0.9561343385880741}\n",
      "{'auroc': 0.9879396715902681, 'accuracy': 0.9535374868004224, 'auprc': 0.9885773373205765, 'f1_score': 0.9547325102880658}\n",
      "{'auroc': 0.988169179689475, 'accuracy': 0.955649419218585, 'auprc': 0.9888637870954944, 'f1_score': 0.956551724137931}\n",
      "{'auroc': 0.9886723129955118, 'accuracy': 0.9538894755367828, 'auprc': 0.9894191970194215, 'f1_score': 0.9549053356282271}\n",
      "{'auroc': 0.9884789908385125, 'accuracy': 0.9535374868004224, 'auprc': 0.9892441835989879, 'f1_score': 0.9547325102880658}\n",
      "{'auroc': 0.9886936280025658, 'accuracy': 0.9542414642731433, 'auprc': 0.989388592548403, 'f1_score': 0.9554183813443072}\n",
      "{'auroc': 0.9880571519779832, 'accuracy': 0.9521295318549806, 'auprc': 0.9885876483818974, 'f1_score': 0.953360768175583}\n",
      "{'auroc': 0.988355562076736, 'accuracy': 0.9560014079549455, 'auprc': 0.9889586805581904, 'f1_score': 0.9571183533447685}\n",
      "{'auroc': 0.9878573857490837, 'accuracy': 0.9507215769095388, 'auprc': 0.9886937252814361, 'f1_score': 0.9519890260631002}\n",
      "{'auroc': 0.9889771671661648, 'accuracy': 0.955649419218585, 'auprc': 0.9897635256733599, 'f1_score': 0.956611570247934}\n",
      "{'auroc': 0.9885880443629738, 'accuracy': 0.9560014079549455, 'auprc': 0.9890186639291737, 'f1_score': 0.9569707401032702}\n",
      "{'auroc': 0.9888953770228189, 'accuracy': 0.9545934530095037, 'auprc': 0.9897258016554934, 'f1_score': 0.9557461406518011}\n",
      "{'auroc': 0.987904972741576, 'accuracy': 0.9535374868004224, 'auprc': 0.988633083829718, 'f1_score': 0.9547014413177762}\n",
      "{'auroc': 0.9887798794264578, 'accuracy': 0.9545934530095037, 'auprc': 0.9894156338445634, 'f1_score': 0.9557461406518011}\n",
      "{'auroc': 0.9887555902323732, 'accuracy': 0.9567053854276664, 'auprc': 0.9896950997330712, 'f1_score': 0.957804459691252}\n",
      "{'auroc': 0.9883218546237207, 'accuracy': 0.9552974304822246, 'auprc': 0.9890617221748329, 'f1_score': 0.956312349501204}\n",
      "{'auroc': 0.9885305434137123, 'accuracy': 0.9507215769095388, 'auprc': 0.989110813282633, 'f1_score': 0.9520219328307059}\n",
      "{'auroc': 0.9883912523211051, 'accuracy': 0.9563533966913059, 'auprc': 0.9890490502965318, 'f1_score': 0.9574759945130316}\n",
      "{'auroc': 0.9884477618746895, 'accuracy': 0.9531854980640619, 'auprc': 0.9892391874763913, 'f1_score': 0.9542168674698795}\n",
      "{'auroc': 0.9886708259019965, 'accuracy': 0.9528335093277015, 'auprc': 0.9894583272241773, 'f1_score': 0.9540466392318244}\n",
      "{'auroc': 0.9882841815879979, 'accuracy': 0.9535374868004224, 'auprc': 0.9890899126417166, 'f1_score': 0.9546703296703297}\n",
      "{'auroc': 0.9892076666610489, 'accuracy': 0.9545934530095037, 'auprc': 0.9900350968942571, 'f1_score': 0.9556853315012023}\n",
      "{'auroc': 0.988708994635558, 'accuracy': 0.9538894755367828, 'auprc': 0.9896169686716083, 'f1_score': 0.9549673427294604}\n",
      "{'auroc': 0.9886430668230429, 'accuracy': 0.9538894755367828, 'auprc': 0.9896669492505944, 'f1_score': 0.9550600343053174}\n",
      "{'auroc': 0.9885964712262276, 'accuracy': 0.9545934530095037, 'auprc': 0.9890797925346186, 'f1_score': 0.9557764826876929}\n",
      "{'auroc': 0.9886564506646813, 'accuracy': 0.9538894755367828, 'auprc': 0.9894967519408313, 'f1_score': 0.954936360509116}\n",
      "{'auroc': 0.9881275410710443, 'accuracy': 0.9552974304822246, 'auprc': 0.9887535741031628, 'f1_score': 0.9563723806252146}\n",
      "{'auroc': 0.9887679826783348, 'accuracy': 0.9552974304822246, 'auprc': 0.9894203405059357, 'f1_score': 0.9565217391304348}\n",
      "{'auroc': 0.9888150739729885, 'accuracy': 0.9535374868004224, 'auprc': 0.9893866979039604, 'f1_score': 0.9546703296703297}\n",
      "{'auroc': 0.9885414487661586, 'accuracy': 0.9531854980640619, 'auprc': 0.9893213322251261, 'f1_score': 0.9542168674698795}\n",
      "{'auroc': 0.9889935251948341, 'accuracy': 0.9567053854276664, 'auprc': 0.9896450895565705, 'f1_score': 0.9577754891864059}\n",
      "{'auroc': 0.9883134277604668, 'accuracy': 0.9542414642731433, 'auprc': 0.9891357117942274, 'f1_score': 0.9553571428571428}\n",
      "{'auroc': 0.9887427020885733, 'accuracy': 0.9545934530095037, 'auprc': 0.9893600045720419, 'f1_score': 0.9558067831449125}\n",
      "{'auroc': 0.9878816749431681, 'accuracy': 0.9535374868004224, 'auprc': 0.9885859838760007, 'f1_score': 0.9545767377838954}\n",
      "{'auroc': 0.9883059922928898, 'accuracy': 0.9549454417458642, 'auprc': 0.9890743883832711, 'f1_score': 0.9559532002752924}\n",
      "{'auroc': 0.9889142135406805, 'accuracy': 0.9535374868004224, 'auprc': 0.9896581777230913, 'f1_score': 0.9545767377838954}\n",
      "{'auroc': 0.9886633904344196, 'accuracy': 0.9560014079549455, 'auprc': 0.9894028893483688, 'f1_score': 0.9571183533447685}\n",
      "{'auroc': 0.9882732762355516, 'accuracy': 0.9545934530095037, 'auprc': 0.9892172406898756, 'f1_score': 0.9556853315012023}\n",
      "{'auroc': 0.988683218347958, 'accuracy': 0.9535374868004224, 'auprc': 0.9893888785429976, 'f1_score': 0.9546703296703297}\n",
      "{'auroc': 0.9883664674291821, 'accuracy': 0.9545934530095037, 'auprc': 0.989162303221544, 'f1_score': 0.95562435500516}\n",
      "{'auroc': 0.987921330770245, 'accuracy': 0.9545934530095037, 'auprc': 0.98905865966995, 'f1_score': 0.9557764826876929}\n",
      "{'auroc': 0.9882271763365749, 'accuracy': 0.9552974304822246, 'auprc': 0.9890095941530235, 'f1_score': 0.956312349501204}\n",
      "{'auroc': 0.9883882781340744, 'accuracy': 0.9531854980640619, 'auprc': 0.9891942561113423, 'f1_score': 0.9544364508393285}\n",
      "{'auroc': 0.987636800210969, 'accuracy': 0.9528335093277015, 'auprc': 0.9886318574993921, 'f1_score': 0.9540466392318244}\n",
      "{'auroc': 0.9886514936862967, 'accuracy': 0.9531854980640619, 'auprc': 0.9894991969782648, 'f1_score': 0.9543739279588337}\n",
      "{'auroc': 0.9882033828403288, 'accuracy': 0.9521295318549806, 'auprc': 0.9891300154512037, 'f1_score': 0.9534246575342465}\n",
      "{'auroc': 0.9876387830023228, 'accuracy': 0.9510735656458993, 'auprc': 0.9883727642473411, 'f1_score': 0.9522500858811405}\n",
      "{'auroc': 0.9893786824153175, 'accuracy': 0.9538894755367828, 'auprc': 0.9898829895719639, 'f1_score': 0.9548742679986221}\n",
      "{'auroc': 0.988578626104043, 'accuracy': 0.9521295318549806, 'auprc': 0.9890078984782694, 'f1_score': 0.9534246575342465}\n",
      "{'auroc': 0.9885503713272507, 'accuracy': 0.9521295318549806, 'auprc': 0.9893705727138321, 'f1_score': 0.953360768175583}\n",
      "{'auroc': 0.9879084426264451, 'accuracy': 0.9563533966913059, 'auprc': 0.9886614972529424, 'f1_score': 0.9572708476912474}\n",
      "{'auroc': 0.9890163272954031, 'accuracy': 0.9535374868004224, 'auprc': 0.9896078647555916, 'f1_score': 0.9545454545454545}\n",
      "{'auroc': 0.9881374550278137, 'accuracy': 0.9528335093277015, 'auprc': 0.988889568861182, 'f1_score': 0.9540466392318244}\n",
      "{'auroc': 0.9883585362637669, 'accuracy': 0.9535374868004224, 'auprc': 0.98923558658825, 'f1_score': 0.9547325102880658}\n",
      "{'auroc': 0.9890237627629801, 'accuracy': 0.9552974304822246, 'auprc': 0.9898275249771333, 'f1_score': 0.9564322469982847}\n",
      "{'auroc': 0.9883778684794668, 'accuracy': 0.9531854980640619, 'auprc': 0.9887863018778142, 'f1_score': 0.9543112332531776}\n",
      "{'auroc': 0.9883719201054053, 'accuracy': 0.9574093629003871, 'auprc': 0.9889334683438511, 'f1_score': 0.9584335279972519}\n",
      "{'auroc': 0.9874449651474849, 'accuracy': 0.9507215769095388, 'auprc': 0.9880037444138041, 'f1_score': 0.9519890260631002}\n",
      "{'auroc': 0.9885444229531892, 'accuracy': 0.955649419218585, 'auprc': 0.9893256301063833, 'f1_score': 0.95679012345679}\n",
      "{'auroc': 0.9883159062496593, 'accuracy': 0.9524815205913411, 'auprc': 0.9890548179475651, 'f1_score': 0.9538145740677386}\n",
      "{'auroc': 0.9882291591279286, 'accuracy': 0.9542414642731433, 'auprc': 0.9888362452432811, 'f1_score': 0.9555099247091035}\n",
      "{'auroc': 0.9885196380612663, 'accuracy': 0.9567053854276664, 'auprc': 0.9893081332468957, 'f1_score': 0.957804459691252}\n",
      "{'auroc': 0.9888274664189499, 'accuracy': 0.9531854980640619, 'auprc': 0.989561728236672, 'f1_score': 0.9544052108330476}\n",
      "{'auroc': 0.9884408221049512, 'accuracy': 0.9535374868004224, 'auprc': 0.9893699631667756, 'f1_score': 0.9545454545454545}\n",
      "{'auroc': 0.9880690487261061, 'accuracy': 0.9535374868004224, 'auprc': 0.9886344385401422, 'f1_score': 0.9547014413177762}\n",
      "{'auroc': 0.988539961672643, 'accuracy': 0.9531854980640619, 'auprc': 0.9891764552944027, 'f1_score': 0.954279821244414}\n",
      "{'auroc': 0.9879466113600065, 'accuracy': 0.9500175994368181, 'auprc': 0.9884591960960325, 'f1_score': 0.9513365318711446}\n",
      "{'auroc': 0.9880839196612599, 'accuracy': 0.9503695881731784, 'auprc': 0.9888108381108572, 'f1_score': 0.9514629948364888}\n",
      "{'auroc': 0.988100277689929, 'accuracy': 0.9552974304822246, 'auprc': 0.9885850742659982, 'f1_score': 0.956312349501204}\n",
      "{'auroc': 0.988190494696529, 'accuracy': 0.9535374868004224, 'auprc': 0.988823840188181, 'f1_score': 0.9547325102880658}\n",
      "{'auroc': 0.9888269707211115, 'accuracy': 0.9549454417458642, 'auprc': 0.9895613549240645, 'f1_score': 0.956043956043956}\n",
      "{'auroc': 0.9879728833454449, 'accuracy': 0.9549454417458642, 'auprc': 0.9887562999414403, 'f1_score': 0.9561343385880741}\n",
      "{'auroc': 0.9885087327088201, 'accuracy': 0.9507215769095388, 'auprc': 0.9893324960978317, 'f1_score': 0.951923076923077}\n",
      "{'auroc': 0.9890049262451186, 'accuracy': 0.9542414642731433, 'auprc': 0.9899364587502504, 'f1_score': 0.9553571428571428}\n",
      "{'auroc': 0.9885761476148508, 'accuracy': 0.9524815205913411, 'auprc': 0.9892732732291201, 'f1_score': 0.9538145740677386}\n",
      "{'auroc': 0.9889870811229341, 'accuracy': 0.9542414642731433, 'auprc': 0.9896073487206192, 'f1_score': 0.955295735900963}\n",
      "{'auroc': 0.9881795893440828, 'accuracy': 0.9560014079549455, 'auprc': 0.9888255545920334, 'f1_score': 0.9570299071845995}\n",
      "{'auroc': 0.9884090974432899, 'accuracy': 0.9524815205913411, 'auprc': 0.9892782713959345, 'f1_score': 0.9536241841291653}\n",
      "{'auroc': 0.9884854349104125, 'accuracy': 0.9542414642731433, 'auprc': 0.9892983266417776, 'f1_score': 0.9553264604810998}\n",
      "{'auroc': 0.9886509979884581, 'accuracy': 0.9552974304822246, 'auprc': 0.9892608842155692, 'f1_score': 0.9564023343631994}\n",
      "{'auroc': 0.988759555815081, 'accuracy': 0.9535374868004224, 'auprc': 0.989687081276742, 'f1_score': 0.9547014413177762}\n",
      "{'auroc': 0.9883580405659284, 'accuracy': 0.9542414642731433, 'auprc': 0.9890405652980488, 'f1_score': 0.9554183813443072}\n",
      "{'auroc': 0.9887293182469348, 'accuracy': 0.9567053854276664, 'auprc': 0.9894410516593669, 'f1_score': 0.9577464788732395}\n",
      "{'auroc': 0.9883530835875436, 'accuracy': 0.9528335093277015, 'auprc': 0.9890448059843293, 'f1_score': 0.9541095890410958}\n",
      "{'auroc': 0.9885047671261125, 'accuracy': 0.955649419218585, 'auprc': 0.9892925482195787, 'f1_score': 0.95679012345679}\n",
      "{'auroc': 0.9876586109158613, 'accuracy': 0.9517775431186202, 'auprc': 0.9882926527785729, 'f1_score': 0.9529047782743211}\n",
      "{'auroc': 0.9882132967970979, 'accuracy': 0.9545934530095037, 'auprc': 0.9887498651094019, 'f1_score': 0.9556853315012023}\n",
      "{'auroc': 0.9882420472717287, 'accuracy': 0.9563533966913059, 'auprc': 0.9888931082058668, 'f1_score': 0.9575342465753426}\n",
      "{'auroc': 0.988214288192775, 'accuracy': 0.9535374868004224, 'auprc': 0.9886543272906135, 'f1_score': 0.9547945205479452}\n",
      "{'auroc': 0.9888002030378346, 'accuracy': 0.9507215769095388, 'auprc': 0.9893249614099422, 'f1_score': 0.9518900343642612}\n",
      "{'auroc': 0.9887174214988119, 'accuracy': 0.9535374868004224, 'auprc': 0.9894377903231216, 'f1_score': 0.9547635366689513}\n",
      "{'auroc': 0.9886202647224736, 'accuracy': 0.9538894755367828, 'auprc': 0.9890837102297246, 'f1_score': 0.9550291795399932}\n",
      "{'auroc': 0.9884784951406741, 'accuracy': 0.955649419218585, 'auprc': 0.9890455721039244, 'f1_score': 0.9566414315209911}\n",
      "{'auroc': 0.9888651394546729, 'accuracy': 0.9545934530095037, 'auprc': 0.9895267811492716, 'f1_score': 0.9558067831449125}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8521 and the array at index 1 has size 2841",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bad8e6f30821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Result/Bootstrapping_predicted_probability_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ensemble'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Result/Bootstrapping_predicted_probability_train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ensemble'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.//Result//Bootstrapping_label_training_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvect_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfusion_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8521 and the array at index 1 has size 2841"
     ]
    }
   ],
   "source": [
    "#This is for the ensemble learning\n",
    "#Change here to choose corpus from STEM_TEXT or CLEAN_TEXT\n",
    "TEXT = 'STEM_TEXT'\n",
    "\n",
    "#Load Dataset\n",
    "Train_Data, Fusion_Data, Val_Data = pd.read_csv(\"./Data/sep_train.csv\"), pd.read_csv(\"./Data/fusion_train.csv\"), pd.read_csv(\"./Data/val.csv\")\n",
    "train_corpus, fusion_corpus, val_corpus= Train_Data[TEXT], Fusion_Data[TEXT], Val_Data[TEXT]\n",
    "\n",
    "#Preprocessing labels form boolean to int\n",
    "Y_train, Y_fusion, Y_val = Train_Data['label'].astype(int), Fusion_Data['label'].astype(int), Val_Data['label'].astype(int)\n",
    "\n",
    "#Instancing vectorizer\n",
    "vectorizer_dict = {\n",
    "    'TFIDF':text.TfidfVectorizer(),\n",
    "    'W2V1': None,\n",
    "    'W2V2': None,\n",
    "    'S2V': None\n",
    "}\n",
    "\n",
    "#bootstrapping experiments: initialize the performance recorders\n",
    "vectorization_time = []\n",
    "modeling_time = []\n",
    "auroc = []\n",
    "auprc = []\n",
    "f1_score_recorder = []\n",
    "accuracy = []\n",
    "predicted_prob = []\n",
    "train_prob = []\n",
    "train_label = []\n",
    "fusion_label = []\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    idx = np.random.choice(train_corpus.shape[0],train_corpus.shape[0],replace=True)\n",
    "    train_corpus_boot = train_corpus.iloc[idx] #New set of training data (separate learners)\n",
    "    Y_train_boot = Y_train[idx] #New set of training data (separate learners)\n",
    "    train_label.append(Y_train_boot)\n",
    "    fusion_label.append(Y_fusion)\n",
    "    \n",
    "    features_fusion = []\n",
    "    features_val = []\n",
    "    features_train = []\n",
    "    #select each of the vectorizer\n",
    "    for vect_NAME in vectorizer_dict:\n",
    "\n",
    "        #Load the embedding for the three sets \n",
    "        if vect_NAME == 'W2V1':\n",
    "            train_emb = np.load('./Embeddings/W2V1_CLEAN_train_sep.npy')[idx]\n",
    "            fusion_emb = np.load('./Embeddings/W2V1_CLEAN_train_fusion.npy')\n",
    "            val_emb = np.load('./Embeddings/W2V1_CLEAN_val.npy')\n",
    "        elif vect_NAME == 'S2V':\n",
    "            train_emb = np.load('./Embeddings/S2V_sep_CLEAN_train.npy')[idx]\n",
    "            fusion_emb = np.load('./Embeddings/S2V_fusion_CLEAN_train.npy')\n",
    "            val_emb = np.load('./Embeddings/S2V_CLEAN_val.npy')\n",
    "        elif vect_NAME == 'W2V2':\n",
    "            train_emb = np.load('./Embeddings/W2V2_CLEAN_train_sep.npy')[idx]\n",
    "            fusion_emb = np.load('./Embeddings/W2V2_CLEAN_train_fusion.npy')\n",
    "            val_emb = np.load('./Embeddings/W2V2_CLEAN_val.npy')\n",
    "        else:\n",
    "            train_emb = vectorizer_dict[vect_NAME].fit_transform(train_corpus_boot)\n",
    "            fusion_emb = vectorizer_dict[vect_NAME].transform(fusion_corpus)\n",
    "            val_emb = vectorizer_dict[vect_NAME].transform(val_corpus)\n",
    "        \n",
    "        if vect_NAME == 'S2V':\n",
    "            clf1 = LogisticRegression(C = 1,max_iter=1000,penalty='l2',class_weight={1:1,0:1})\n",
    "            clf2 = LogisticRegression(C = 1,max_iter=1000,penalty='l2',class_weight={1:2,0:1})\n",
    "            clf3 = LogisticRegression(C = 1,max_iter=1000,penalty='l2',class_weight={1:5,0:1})\n",
    "        else:\n",
    "            clf1 = LogisticRegression(C = 10,max_iter=1000,penalty='l2',class_weight={1:1,0:1})\n",
    "            clf2 = LogisticRegression(C = 10,max_iter=1000,penalty='l2',class_weight={1:2,0:1})\n",
    "            clf3 = LogisticRegression(C = 10,max_iter=1000,penalty='l2',class_weight={1:5,0:1})\n",
    "        \n",
    "        clf1.fit(train_emb,Y_train_boot)\n",
    "        clf2.fit(train_emb,Y_train_boot)\n",
    "        clf3.fit(train_emb,Y_train_boot)\n",
    "        \n",
    "        features_fusion.append(clf1.predict_proba(fusion_emb)[:, 1])\n",
    "        features_fusion.append(clf2.predict_proba(fusion_emb)[:, 1])\n",
    "        features_fusion.append(clf3.predict_proba(fusion_emb)[:, 1])\n",
    "        \n",
    "        features_val.append(clf1.predict_proba(val_emb)[:, 1])\n",
    "        features_val.append(clf2.predict_proba(val_emb)[:, 1])\n",
    "        features_val.append(clf3.predict_proba(val_emb)[:, 1])\n",
    "        \n",
    "        features_train.append(clf1.predict_proba(train_emb)[:, 1])\n",
    "        features_train.append(clf2.predict_proba(train_emb)[:, 1])\n",
    "        features_train.append(clf3.predict_proba(train_emb)[:, 1])\n",
    "    \n",
    "    X_fusion = np.array(features_fusion).T\n",
    "    X_val = np.array(features_val).T\n",
    "    X_train = np.array(features_train).T\n",
    "    \n",
    "    vectorization_time.append(0)\n",
    "    tik = time.time()\n",
    "    clf = LogisticRegression(C = 0.1,max_iter=1000,penalty='l2',class_weight={1:1,0:1})\n",
    "    clf.fit(X_fusion,Y_fusion)\n",
    "    tok = time.time()\n",
    "    modeling_time.append(tok-tik)\n",
    "    \n",
    "    preds, pred_probs = getPredicts(clf, X_val)\n",
    "    predicted_prob.append(pred_probs)\n",
    "    result = modelEval(Y_val, preds, pred_probs)\n",
    "    \n",
    "    #Get training probability\n",
    "    train_preds, train_pred_probs = getPredicts(clf, np.row_stack([X_train,X_fusion]))\n",
    "    train_prob.append(train_pred_probs)\n",
    "    \n",
    "    print(result)\n",
    "\n",
    "    auroc.append(result['auroc'])\n",
    "    auprc.append(result['auprc'])\n",
    "    accuracy.append(result['accuracy'])\n",
    "    f1_score_recorder.append(result['f1_score'])\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame({'AUROC': auroc,'AUPRC': auprc,'Accuracy': accuracy,'F1_score': f1_score_recorder,'Vectorization_Time': vectorization_time,'Modeling_Time': modeling_time})\n",
    "result_df.to_csv('./Result/Bootstrapping_'+'ensemble'+'.csv', index = False)\n",
    "np.save('./Result/Bootstrapping_predicted_probability_'+'ensemble'+'.npy',np.array(predicted_prob))\n",
    "np.save('./Result/Bootstrapping_predicted_probability_train_'+'ensemble'+'.npy',np.array(train_prob))\n",
    "np.save('.//Result//Bootstrapping_label_training_'+vect_NAME+'.npy',np.row_stack([np.array(train_label),np.array(fusion_label)]))\n",
    "print(result_df.mean())\n",
    "print(result_df.quantile(0.025))\n",
    "print(result_df.quantile(0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
